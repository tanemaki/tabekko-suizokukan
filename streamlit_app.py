import urllib.request
from pathlib import Path

import cv2
import matplotlib as mpl
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import streamlit as st

from tabekko.estimator import TabekkoSuizokukanEstimator
from tabekko.preprocessor import ImagePreProcessor

# ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã® .fonts ãƒ•ã‚©ãƒ«ãƒ€ãªã©ï¼‰
font_dir = Path(".fonts")
font_dir.mkdir(exist_ok=True)
font_path = font_dir / "NotoSansCJKjp-Regular.otf"


# ãƒ•ã‚©ãƒ³ãƒˆãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if not font_path.exists():
    print("Downloading Noto Sans CJK JP font...")
    url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/Japanese/NotoSansCJKjp-Regular.otf"
    urllib.request.urlretrieve(url, font_path)
    print("Font downloaded to:", font_path)

# ãƒ•ã‚©ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§è¨­å®š
jp_font = fm.FontProperties(fname=str(font_path))
fm.fontManager.addfont(str(font_path))
mpl.rcParams["font.family"] = jp_font.get_name()


def visualize_image_processor(image_preprocessor):
    # ç”»åƒä¸­ã®æ­£æ–¹å½¢ã®æ ç·šã‚’èªè­˜ã—ã€è§’ã®4ç‚¹ã®åº§æ¨™ã‚’èª­ã¿å–ã‚‹å‡¦ç†ã‚’å¯è¦–åŒ–
    image_columns = st.columns(3)
    image_columns[0].image(
        image_preprocessor.resized_original_image,
        channels="BGR",
        caption="æ’®å½±ç”»åƒï¼ˆ640x480ã«ãƒªã‚µã‚¤ã‚ºæ¸ˆã¿ï¼‰",
    )
    image_columns[1].image(
        image_preprocessor.edges, channels="GRAY", caption="ã‚¨ãƒƒã‚¸æ¤œå‡ºå¾Œ"
    )
    # Display the image with detected squares
    image_columns[2].image(
        image_preprocessor.annotated_image, channels="BGR", caption="æ­£æ–¹æ ã®æ¤œå‡º"
    )

    if image_preprocessor.num_squares == 0:
        # æ ç·šãŒè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ã‚¹ãƒˆãƒƒãƒ—
        st.warning(
            "æ­£æ–¹å½¢ã®æ ç·šãŒã†ã¾ãè¦‹ã¤ã‘ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸğŸ˜­ã€€ä»–ã®ç”»åƒã‚’å…¥ã‚Œã¦ã¿ã¦ãã ã•ã„ğŸ™‡â€â™‚ï¸"
        )
        st.stop()

    # å°å½¢è£œæ­£ã§åˆ‡ã‚Šå‡ºã—ãŸæ­£æ–¹ç”»åƒã®å‡¦ç†ã‚’å¯è¦–åŒ–
    image_columns = st.columns(4)
    image_columns[0].image(
        image_preprocessor.square_image,
        channels="BGR",
        width=200,
        caption="æ¤œå‡ºé ˜åŸŸã®æŠ½å‡º",
    )
    image_columns[1].image(image_preprocessor.binary_image, width=200, caption="äºŒå€¤åŒ–")
    image_columns[2].image(
        image_preprocessor.noise_removed_image, width=200, caption="ãƒã‚¤ã‚ºé™¤å»"
    )
    image_columns[3].image(
        image_preprocessor.standardized_image,
        channels="GRAY",
        width=200,
        caption=f"{image_preprocessor.edge_length}x{image_preprocessor.edge_length}ã®ç”»åƒ",
    )


def render_page():
    # Show the page title and description.
    st.set_page_config(page_title="ãŸã¹ã£ã“æ°´æ—é¤¨", page_icon="ğŸŸ", layout="wide")
    st.title("ğŸŸãŸã¹ã£ã“æ°´æ—é¤¨ã®ã‚­ãƒ£ãƒ©å½“ã¦ã‚¢ãƒ—ãƒª")
    st.write(
        """
        ã€Œé›£ã—ã„ã“ã¨ã¯é‡å­ã‚¢ãƒ‹ãƒ¼ãƒ©ãƒ¼ã«ã‚„ã‚‰ã›ã‚ˆã†ã€ã‚’åˆè¨€è‘‰ã«ã€ã“ã®ã‚¢ãƒ—ãƒªã¯é–‹ç™ºã•ã‚Œã¾ã—ãŸã€‚
        ã“ã®ã‚¢ãƒ—ãƒªã‚’ä½¿ã†ã“ã¨ã§ã€é•·å¹´äººé¡ã‚’æ‚©ã¾ã›ã¦ããŸã€ŒãŸã¹ã£å­æ°´æ—é¤¨ã€ã®ã‚­ãƒ£ãƒ©å½“ã¦ãŒé©šãã»ã©ç°¡å˜ã«ã€‚
        ç”¨æ„ã™ã‚‹ã®ã¯ã€5cmå››æ–¹ã®æ­£æ–¹å½¢ãŒæã‹ã‚ŒãŸç™½ã„ã‚³ãƒ”ãƒ¼ç”¨ç´™ã¨ã€ŒãŸã¹ã£ã“æ°´æ—é¤¨ã€ã®ãƒ“ã‚¹ã‚±ãƒƒãƒˆã ã‘ã€‚
        é»’ã®ãƒœãƒ¼ãƒ«ãƒšãƒ³ã§æã„ãŸæ­£æ–¹å½¢ã®ä¸­ã«ã€ãƒ“ã‚¹ã‚±ãƒƒãƒˆã‚’ç½®ã„ã¦ã­ã€‚
        ä¸‹ã®å›³ã«ã‚ã‚‹ã‚­ãƒ£ãƒ©ã¨è¿‘ã„è§’åº¦ã§ç½®ãã¨æ­£ç­”ç‡ãŒãã‚“ã¨ä¸ŠãŒã‚‹ã‚ˆã€‚
        æ˜¯éã‚ãªãŸã‚‚ãŠè©¦ã—ã‚ã‚Œã€‚
        """
    )

    st.image(
        "./data/tabekko_table.jpg", caption="ãŸã¹ã£ã“æ°´æ—é¤¨ã®ã‚­ãƒ£ãƒ©ä¸€è¦§è¡¨", width=600
    )

    uploaded_file = st.file_uploader(
        "ã‚­ãƒ£ãƒ©å½“ã¦ã®ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["png", "jpg", "jpeg"]
    )

    if uploaded_file is None:
        st.warning("ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)

    # OpenCVã§ç”»åƒã¨ã—ã¦èª­ã¿è¾¼ã¿ï¼ˆBGRå½¢å¼ï¼‰
    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

    # ç”»åƒã‚’è¡¨ç¤º
    columns = st.columns(2)
    columns[0].image(image, channels="BGR", caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒ")

    edge_length = 28

    image_preprocessor = ImagePreProcessor(image, edge_length)

    tabekko_df = pd.read_csv("data/ginbis_tabekko_suizokukan.csv")
    tabekko_df = tabekko_df.set_index("id")

    dataset = np.load("data/250512a/dataset.npz")

    # ä½¿ç”¨å¯èƒ½ãªå‹•ç‰©IDã®ãƒªã‚¹ãƒˆ
    unique_class_ids = np.unique(dataset["labels"])

    # å­¦ç¿’æ¸ˆã¿ã®QUBOè¡Œåˆ—ç­‰ã‚’èª­ã¿è¾¼ã‚€
    loaded_result = np.load("data/250512a/result.npz")

    qubo = loaded_result["qubo"]

    estimator = TabekkoSuizokukanEstimator(
        qubo,
        unique_class_ids,
        loaded_result["nodes_per_class"],
        edge_length,
        tabekko_df,
    )

    visualize_image_processor(image_preprocessor)
    estimated_result = estimator.estimate(image_preprocessor.standardized_image)

    columns[1].info(f"ã“ã‚Œã¯ãŸã¶ã‚“ã€Œ{estimated_result['estimated_class_name']}ã€ã ã‚ˆï¼")
    result_df = pd.DataFrame(
        {
            "åå‰": estimated_result["sorted_class_names"].values[:5],
            "ç¢ºç‡": estimated_result["sorted_probabilities"][:5],
        }
    )

    result_df.set_index("åå‰", inplace=True)
    figure, ax = plt.subplots(figsize=(10, 5))
    result_df.plot(kind="barh", ax=ax)
    ax.set_title("ç¢ºç‡ã®é«˜ã„é †ã«ä¸Šä½5ã¤")
    ax.set_xlabel("ç¢ºç‡")
    ax.legend().remove()
    plt.gca().invert_yaxis()
    columns[1].pyplot(figure)


if __name__ == "__main__":
    render_page()
